{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if needed: pip install yfinance pandas numpy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"FTSE100_raw.csv\")\n",
    "print(data.shape)\n",
    "data = pd.read_csv(\"DAX.csv\")\n",
    "print(data.shape)\n",
    "data = pd.read_csv(\"SP500_raw\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Target', 'Lag_1', 'Lag_2', 'Lag_3', 'Lag_4', 'Lag_5',\n",
      "       'day_of_week', 'month', 'day_of_month'],\n",
      "      dtype='object')\n",
      "            Date    Target     Lag_1     Lag_2     Lag_3     Lag_4     Lag_5  \\\n",
      "0     2015-01-12 -0.002819 -0.008439  0.017730  0.011563 -0.008933 -0.018447   \n",
      "1     2015-01-13  0.004483 -0.008127 -0.008439  0.017730  0.011563 -0.008933   \n",
      "2     2015-01-14  0.025468 -0.002582 -0.008127 -0.008439  0.017730  0.011563   \n",
      "3     2015-01-15  0.029252 -0.005830 -0.002582 -0.008127 -0.008439  0.017730   \n",
      "4     2015-01-16  0.018482 -0.009291 -0.005830 -0.002582 -0.008127 -0.008439   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "2248  2023-12-15  0.007482  0.002644  0.013558  0.004589  0.003917  0.004087   \n",
      "2249  2023-12-18  0.007186 -0.000076  0.002644  0.013558  0.004589  0.003917   \n",
      "2250  2023-12-19  0.002767  0.004518 -0.000076  0.002644  0.013558  0.004589   \n",
      "2251  2023-12-20  0.017930  0.005849  0.004518 -0.000076  0.002644  0.013558   \n",
      "2252  2023-12-21  0.004851 -0.014793  0.005849  0.004518 -0.000076  0.002644   \n",
      "\n",
      "      day_of_week  month  day_of_month  \n",
      "0               0      1            12  \n",
      "1               1      1            13  \n",
      "2               2      1            14  \n",
      "3               3      1            15  \n",
      "4               4      1            16  \n",
      "...           ...    ...           ...  \n",
      "2248            4     12            15  \n",
      "2249            0     12            18  \n",
      "2250            1     12            19  \n",
      "2251            2     12            20  \n",
      "2252            3     12            21  \n",
      "\n",
      "[2253 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "#start_date = \"2015-01-01\"\n",
    "#end_date = \"2023-12-31\"\n",
    "data_raw = pd.read_csv(\"sp500_full.csv\")\n",
    "print(data_raw.columns)\n",
    "print(data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date  Target     Lag_1     Lag_2     Lag_3     Lag_4     Lag_5  \\\n",
      "0     2015-01-12       0 -0.008439  0.017730  0.011563 -0.008933 -0.018447   \n",
      "1     2015-01-13       1 -0.008127 -0.008439  0.017730  0.011563 -0.008933   \n",
      "2     2015-01-14       1 -0.002582 -0.008127 -0.008439  0.017730  0.011563   \n",
      "3     2015-01-15       1 -0.005830 -0.002582 -0.008127 -0.008439  0.017730   \n",
      "4     2015-01-16       1 -0.009291 -0.005830 -0.002582 -0.008127 -0.008439   \n",
      "...          ...     ...       ...       ...       ...       ...       ...   \n",
      "2248  2023-12-15       1  0.002644  0.013558  0.004589  0.003917  0.004087   \n",
      "2249  2023-12-18       1 -0.000076  0.002644  0.013558  0.004589  0.003917   \n",
      "2250  2023-12-19       1  0.004518 -0.000076  0.002644  0.013558  0.004589   \n",
      "2251  2023-12-20       1  0.005849  0.004518 -0.000076  0.002644  0.013558   \n",
      "2252  2023-12-21       1 -0.014793  0.005849  0.004518 -0.000076  0.002644   \n",
      "\n",
      "      day_of_week  month  day_of_month  \n",
      "0               0      1            12  \n",
      "1               1      1            13  \n",
      "2               2      1            14  \n",
      "3               3      1            15  \n",
      "4               4      1            16  \n",
      "...           ...    ...           ...  \n",
      "2248            4     12            15  \n",
      "2249            0     12            18  \n",
      "2250            1     12            19  \n",
      "2251            2     12            20  \n",
      "2252            3     12            21  \n",
      "\n",
      "[2253 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "data_raw[\"Target\"] = (data_raw[\"Target\"] > 0).astype(int)\n",
    "print(data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.to_csv(\"SP500_classification.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_german_float(value):\n",
    "    if isinstance(value, str):\n",
    "        # Remove periods (thousands separator)\n",
    "        cleaned_value = value.replace('.', '')\n",
    "        # Replace comma (decimal separator) with period\n",
    "        cleaned_value = cleaned_value.replace(',', '.')\n",
    "        try:\n",
    "            return float(cleaned_value)\n",
    "        except ValueError:\n",
    "            return np.nan # Or handle other errors as needed\n",
    "    return value # Return as is if not a string (e.g., already a number or NaN)\n",
    "data_raw['Price'] = data_raw['Price'].apply(convert_german_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date  LogReturn  Target\n",
      "0     12/29/2023        NaN       0\n",
      "1     12/28/2023  -0.002995       1\n",
      "2     12/27/2023   0.002423       0\n",
      "3     12/22/2023  -0.002146       1\n",
      "4     12/21/2023  -0.001124       1\n",
      "...          ...        ...     ...\n",
      "2279  01/08/2015   0.019410       0\n",
      "2280  01/07/2015  -0.033009       0\n",
      "2281  01/06/2015  -0.005111       0\n",
      "2282  01/05/2015   0.000370       0\n",
      "2283  01/02/2015   0.030314       0\n",
      "\n",
      "[2284 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4c/gx6ft8qx2c90jb6mwvlx3gcw0000gn/T/ipykernel_6329/2792111517.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# STEP 2: Clean and enrich the data\n",
    "# -----------------------------------\n",
    "# First compute daily log return\n",
    "data_raw[\"LogReturn\"] = np.log(data_raw[\"Price\"] / data_raw[\"Price\"].shift(1))\n",
    "\n",
    "# Define the prediction target: \"HORIZON\"-day forward cumulative return\n",
    "HORIZON = 5 # cumulative return of 5 days \n",
    "cum_return = data_raw[\"LogReturn\"].rolling(window=HORIZON).sum().shift(-HORIZON)\n",
    "# Print more values: show the first 20 and last 20 values, plus summary stats\n",
    "data_raw[\"Target\"] = (cum_return > 0).astype(int)\n",
    "\n",
    "# Keep only date, log return and target\n",
    "data = data_raw[[\"Date\",\"LogReturn\", \"Target\"]]\n",
    "print(data)\n",
    "\n",
    "# Drop the first row with NaN return (from shift operation)\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4c/gx6ft8qx2c90jb6mwvlx3gcw0000gn/T/ipykernel_6329/2107050231.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f\"Lag_{lag}\"] = data[\"LogReturn\"].shift(lag)\n",
      "/var/folders/4c/gx6ft8qx2c90jb6mwvlx3gcw0000gn/T/ipykernel_6329/2107050231.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f\"Lag_{lag}\"] = data[\"LogReturn\"].shift(lag)\n",
      "/var/folders/4c/gx6ft8qx2c90jb6mwvlx3gcw0000gn/T/ipykernel_6329/2107050231.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f\"Lag_{lag}\"] = data[\"LogReturn\"].shift(lag)\n",
      "/var/folders/4c/gx6ft8qx2c90jb6mwvlx3gcw0000gn/T/ipykernel_6329/2107050231.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f\"Lag_{lag}\"] = data[\"LogReturn\"].shift(lag)\n",
      "/var/folders/4c/gx6ft8qx2c90jb6mwvlx3gcw0000gn/T/ipykernel_6329/2107050231.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f\"Lag_{lag}\"] = data[\"LogReturn\"].shift(lag)\n",
      "/var/folders/4c/gx6ft8qx2c90jb6mwvlx3gcw0000gn/T/ipykernel_6329/2107050231.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.dropna(inplace=True)  # drop rows with NaNs introduced by lagging\n",
      "/var/folders/4c/gx6ft8qx2c90jb6mwvlx3gcw0000gn/T/ipykernel_6329/2107050231.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.drop(columns=[\"LogReturn\"], inplace=True) # LogReturn no more needed\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# STEP 3: Create lag features\n",
    "# -----------------------------------\n",
    "N_LAGS = 5\n",
    "for lag in range(1, N_LAGS + 1):\n",
    "    data[f\"Lag_{lag}\"] = data[\"LogReturn\"].shift(lag) \n",
    "\n",
    "data.dropna(inplace=True)  # drop rows with NaNs introduced by lagging\n",
    "\n",
    "data.drop(columns=[\"LogReturn\"], inplace=True) # LogReturn no more needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date  Target     Lag_1     Lag_2     Lag_3     Lag_4     Lag_5  \\\n",
      "6    2023-12-19       1  0.002731 -0.001124 -0.002146  0.002423 -0.002995   \n",
      "7    2023-12-18       1  0.000679  0.002731 -0.001124 -0.002146  0.002423   \n",
      "8    2023-12-15       1 -0.005621  0.000679  0.002731 -0.001124 -0.002146   \n",
      "9    2023-12-14       0  0.006041 -0.005621  0.000679  0.002731 -0.001124   \n",
      "10   2023-12-13       0  0.000047  0.006041 -0.005621  0.000679  0.002731   \n",
      "...         ...     ...       ...       ...       ...       ...       ...   \n",
      "2279 2015-01-08       0 -0.013731 -0.016134  0.012544 -0.021717 -0.013382   \n",
      "2280 2015-01-07       0  0.019410 -0.013731 -0.016134  0.012544 -0.021717   \n",
      "2281 2015-01-06       0 -0.033009  0.019410 -0.013731 -0.016134  0.012544   \n",
      "2282 2015-01-05       0 -0.005111 -0.033009  0.019410 -0.013731 -0.016134   \n",
      "2283 2015-01-02       0  0.000370 -0.005111 -0.033009  0.019410 -0.013731   \n",
      "\n",
      "      day_of_week  month  day_of_month  \n",
      "6               1     12            19  \n",
      "7               0     12            18  \n",
      "8               4     12            15  \n",
      "9               3     12            14  \n",
      "10              2     12            13  \n",
      "...           ...    ...           ...  \n",
      "2279            3      1             8  \n",
      "2280            2      1             7  \n",
      "2281            1      1             6  \n",
      "2282            0      1             5  \n",
      "2283            4      1             2  \n",
      "\n",
      "[2278 rows x 10 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4c/gx6ft8qx2c90jb6mwvlx3gcw0000gn/T/ipykernel_6329/2948465921.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"Date\"] = pd.to_datetime(data[\"Date\"], format=\"%m/%d/%Y\")\n",
      "/var/folders/4c/gx6ft8qx2c90jb6mwvlx3gcw0000gn/T/ipykernel_6329/2948465921.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"day_of_week\"] = data[\"Date\"].dt.dayofweek   # Monday = 0, Sunday = 6\n",
      "/var/folders/4c/gx6ft8qx2c90jb6mwvlx3gcw0000gn/T/ipykernel_6329/2948465921.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"month\"] = data[\"Date\"].dt.month             # 1 to 12\n",
      "/var/folders/4c/gx6ft8qx2c90jb6mwvlx3gcw0000gn/T/ipykernel_6329/2948465921.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"day_of_month\"] = data[\"Date\"].dt.day        # 1 to 31\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# STEP 4: Add temporal features\n",
    "# -----------------------------------\n",
    "data[\"Date\"] = pd.to_datetime(data[\"Date\"], format=\"%m/%d/%Y\")\n",
    "data[\"day_of_week\"] = data[\"Date\"].dt.dayofweek   # Monday = 0, Sunday = 6\n",
    "data[\"month\"] = data[\"Date\"].dt.month             # 1 to 12\n",
    "data[\"day_of_month\"] = data[\"Date\"].dt.day        # 1 to 31\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"DAX_classification.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# STEP 5: Define training set andcommon test set (latest 20%)\n",
    "# -----------------------------------\n",
    "full_train_size = int(len(data) * 0.8)\n",
    "train_data_only = data.iloc[:full_train_size].copy()\n",
    "common_test = data.iloc[full_train_size:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# STEP 6: Simulate 1 single agent and 3 federated agents\n",
    "# -----------------------------------\n",
    "agent_data = {}\n",
    "agent_data[\"SingleAgent_Train\"] = train_data_only.copy()\n",
    "agent_data[\"SingleAgent_Test\"] = common_test.copy()\n",
    "\n",
    "# Without shuffling: split for federated agents\n",
    "federated_data = train_data_only.copy()\n",
    "splits = np.array_split(federated_data, 3)\n",
    "\n",
    "# With shuffling: shuffle and split for federated agents\n",
    "#shuffled = train_data_only.sample(frac=1, random_state=4)\n",
    "#splits = np.array_split(shuffled, 3)\n",
    "\n",
    "# Assign to agents\n",
    "for i, df in enumerate(splits):\n",
    "    agent_data[f\"Agent_{i+1}_Train\"] = df.sort_index()\n",
    "    agent_data[f\"Agent_{i+1}_Test\"] = common_test.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# STEP 7: Preview the datasets\n",
    "# -----------------------------------\n",
    "for name, df in agent_data.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(df.head())\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if needed: pip install tensorflow scikit-learn matplotlib\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# STEP 1: Features and target column names\n",
    "# -----------------------------------\n",
    "feature_cols = [f\"Lag_{i}\" for i in range(1, 6)] + [\"day_of_week\", \"month\", \"day_of_month\"]\n",
    "target_col = \"Target\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# STEP 2: Function to build the model\n",
    "# -----------------------------------\n",
    "def build_model(input_dim):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(150, activation='relu', input_shape=(input_dim,)),\n",
    "        layers.Dense(10, activation='relu'),\n",
    "        layers.Dense(1)  # Linear output for regression\n",
    "    ])\n",
    "    model.compiale(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# STEP 3: Plot training loss and MAE\n",
    "# -----------------------------------\n",
    "def plot_training(history, title):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(history.history['loss'], label='MSE')\n",
    "    plt.plot(history.history['mae'], label='MAE')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# STEP 4: Function to train the model\n",
    "# -----------------------------------\n",
    "def train_model(train_df, label=\"\"):\n",
    "    X = train_df[feature_cols].values\n",
    "    y = train_df[target_col].values\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X) # Normalization\n",
    "\n",
    "    model = build_model(X.shape[1])\n",
    "    print(f\"\\nTraining model on {label}...\")\n",
    "    history = model.fit(X_scaled, y, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "    plot_training(history, title=f\"{label} Training Metrics\")\n",
    "    return model, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# STEP 5: Function to evaluate the model\n",
    "# -----------------------------------\n",
    "def evaluate_model(model, scaler, test_df):\n",
    "    X_test = scaler.transform(test_df[feature_cols].values)\n",
    "    y_true = test_df[target_col].values\n",
    "    y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    print(f\"Test MSE: {mse:.6f}, MAE: {mae:.6f}\")\n",
    "    return mse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# STEP 6: Single-agent model \n",
    "# -----------------------\n",
    "single_model, single_scaler = train_model(agent_data[\"SingleAgent_Train\"], label=\"SingleAgent\")\n",
    "evaluate_model(single_model, single_scaler, agent_data[\"SingleAgent_Test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# STEP 7: Per-agent models\n",
    "# -----------------------\n",
    "agent_models = {}\n",
    "for i in range(1, 4):\n",
    "    agent_name = f\"Agent_{i}_Train\"\n",
    "    test_name = f\"Agent_{i}_Test\"\n",
    "    model, scaler = train_model(agent_data[agent_name], label=agent_name)\n",
    "    evaluate_model(model, scaler, agent_data[test_name])\n",
    "    agent_models[agent_name] = {\"model\": model, \"scaler\": scaler}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
