{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if needed: pip install yfinance pandas numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Price', 'Open', 'High', 'Low', 'Vol.', 'Change %'], dtype='object')\n",
      "            Date     Price      Open      High       Low     Vol. Change %\n",
      "0     12/29/2023  7,733.24  7,722.74  7,746.91  7,719.02  225.64M    0.14%\n",
      "1     12/28/2023  7,722.74  7,724.95  7,745.99  7,708.74  316.82M   -0.03%\n",
      "2     12/27/2023  7,724.95  7,697.51  7,759.74  7,697.51  409.46M    0.36%\n",
      "3     12/22/2023  7,697.51  7,694.73  7,715.21  7,676.43  320.56M    0.04%\n",
      "4     12/21/2023  7,694.73  7,715.68  7,715.68  7,668.41  562.95M   -0.27%\n",
      "...          ...       ...       ...       ...       ...      ...      ...\n",
      "2267  01/08/2015  6,569.96  6,419.83  6,580.82  6,419.83  910.04M    2.34%\n",
      "2268  01/07/2015  6,419.83  6,366.51  6,459.74  6,366.51  709.50M    0.84%\n",
      "2269  01/06/2015  6,366.51  6,417.16  6,452.66  6,328.59  793.26M   -0.79%\n",
      "2270  01/05/2015  6,417.16  6,547.80  6,576.74  6,404.49  750.52M   -2.00%\n",
      "2271  01/02/2015  6,547.80  6,566.09  6,607.89  6,510.60  378.93M   -0.28%\n",
      "\n",
      "[2272 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#data_raw = pd.read_csv(\"SP500_raw.csv\")\n",
    "#data_raw = pd.read_csv(\"DAX.csv\")\n",
    "data_raw = pd.read_csv(\"FTSE100_raw.csv\")\n",
    "print(data_raw.columns)\n",
    "print(data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_german_float(value):\n",
    "    if isinstance(value, str):\n",
    "        # Remove periods (thousands separator)\n",
    "        cleaned_value = value.replace('.', '')\n",
    "        # Replace comma (decimal separator) with period\n",
    "        cleaned_value = cleaned_value.replace(',', '.')\n",
    "        try:\n",
    "            return float(cleaned_value)\n",
    "        except ValueError:\n",
    "            return np.nan # Or handle other errors as needed\n",
    "    return value # Return as is if not a string (e.g., already a number or NaN)\n",
    "data_raw['Price'] = data_raw['Price'].apply(convert_german_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         NaN\n",
      "1         NaN\n",
      "2         NaN\n",
      "3         NaN\n",
      "4         NaN\n",
      "5    0.002273\n",
      "6    0.011030\n",
      "7    0.014404\n",
      "8    0.015864\n",
      "9    0.005963\n",
      "Name: LogReturn, dtype: float64\n",
      "            Date    Price      Open      High       Low     Vol. Change %  \\\n",
      "0     12/20/2023  7.71568  7,638.03  7,762.88  7,637.93  875.63M    1.02%   \n",
      "1     12/19/2023  7.63803  7,614.48  7,642.15  7,605.35  935.13M    0.31%   \n",
      "2     12/18/2023  7.61448  7,576.36  7,630.57  7,557.24  661.07M    0.50%   \n",
      "3     12/15/2023  7.57636  7,648.98  7,668.22  7,569.00    1.58B   -0.95%   \n",
      "4     12/14/2023  7.64898  7,548.44  7,724.81  7,548.44    1.44B    1.33%   \n",
      "...          ...      ...       ...       ...       ...      ...      ...   \n",
      "2262  01/08/2015  6.56996  6,419.83  6,580.82  6,419.83  910.04M    2.34%   \n",
      "2263  01/07/2015  6.41983  6,366.51  6,459.74  6,366.51  709.50M    0.84%   \n",
      "2264  01/06/2015  6.36651  6,417.16  6,452.66  6,328.59  793.26M   -0.79%   \n",
      "2265  01/05/2015  6.41716  6,547.80  6,576.74  6,404.49  750.52M   -2.00%   \n",
      "2266  01/02/2015  6.54780  6,566.09  6,607.89  6,510.60  378.93M   -0.28%   \n",
      "\n",
      "      LogReturn  Target  \n",
      "0     -0.002719       0  \n",
      "1      0.010115       0  \n",
      "2      0.003088       1  \n",
      "3      0.005019       1  \n",
      "4     -0.009539       0  \n",
      "...         ...     ...  \n",
      "2262  -0.010530       0  \n",
      "2263   0.023116       0  \n",
      "2264   0.008340       1  \n",
      "2265  -0.007924       1  \n",
      "2266  -0.020153       0  \n",
      "\n",
      "[2267 rows x 9 columns]\n",
      "         Date  LogReturn  Target\n",
      "0  12/20/2023  -0.002719       0\n",
      "1  12/19/2023   0.010115       0\n",
      "2  12/18/2023   0.003088       1\n",
      "3  12/15/2023   0.005019       1\n",
      "4  12/14/2023  -0.009539       0\n",
      "5  12/13/2023   0.013231       1\n",
      "6  12/12/2023   0.000751       1\n",
      "7  12/11/2023  -0.000281       0\n",
      "8  12/08/2023  -0.001269       0\n",
      "9  12/07/2023   0.005409       1\n",
      "Ratio of Targets (mean of Target column): 0.4998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4c/gx6ft8qx2c90jb6mwvlx3gcw0000gn/T/ipykernel_41482/3958822579.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# STEP 2: Clean and enrich the data\n",
    "# -----------------------------------\n",
    "# First compute daily log return\n",
    "data_raw[\"LogReturn\"] = np.log(data_raw[\"Price\"].shift(1) / data_raw[\"Price\"])\n",
    "\n",
    "# Define the prediction target: \"HORIZON\"-day forward cumulative return\n",
    "HORIZON = 5 # cumulative return of 5 days \n",
    "cum_return = data_raw[\"LogReturn\"].rolling(window=HORIZON).sum()\n",
    "\n",
    "print(cum_return.head(10))\n",
    "# Drop rows where cum_return is NaN before creating the Target column\n",
    "mask = cum_return.notna()\n",
    "data_raw = data_raw[mask].reset_index(drop=True)\n",
    "cum_return = cum_return[mask].reset_index(drop=True)\n",
    "median = np.abs(cum_return).median()\n",
    "#data_raw[\"Target\"] = (cum_return > 0).astype(int)\n",
    "data_raw[\"Target\"] = (np.abs(cum_return) > median).astype(int)\n",
    "\n",
    "print(data_raw)\n",
    "\n",
    "# Keep only date, log return and target\n",
    "data = data_raw[[\"Date\",\"LogReturn\", \"Target\"]]\n",
    "\n",
    "# Drop the first row with NaN return (from shift operation)\n",
    "data.dropna(inplace=True)\n",
    "print(data.head(10))\n",
    "# INSERT_YOUR_CODE\n",
    "target_ratio = data[\"Target\"].mean()\n",
    "print(f\"Ratio of Targets (mean of Target column): {target_ratio:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  LogReturn  Target  Lag_1  Lag_2  Lag_3  Lag_4  Lag_5  \\\n",
      "0  12/20/2023  -0.002719       0    0.0    1.0    1.0    0.0    1.0   \n",
      "1  12/19/2023   0.010115       0    1.0    1.0    0.0    1.0    1.0   \n",
      "2  12/18/2023   0.003088       1    1.0    0.0    1.0    1.0    0.0   \n",
      "\n",
      "   Date_Lag_1  Date_Lag_2  Date_Lag_3  Date_Lag_4  Date_Lag_5  \n",
      "0  12/19/2023  12/18/2023  12/15/2023  12/14/2023  12/13/2023  \n",
      "1  12/18/2023  12/15/2023  12/14/2023  12/13/2023  12/12/2023  \n",
      "2  12/15/2023  12/14/2023  12/13/2023  12/12/2023  12/11/2023  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4c/gx6ft8qx2c90jb6mwvlx3gcw0000gn/T/ipykernel_41482/3460679292.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f\"Lag_{lag}\"] = data[\"Target\"].shift(-(lag))\n",
      "/var/folders/4c/gx6ft8qx2c90jb6mwvlx3gcw0000gn/T/ipykernel_41482/3460679292.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f\"Lag_{lag}\"] = data[\"Target\"].shift(-(lag))\n",
      "/var/folders/4c/gx6ft8qx2c90jb6mwvlx3gcw0000gn/T/ipykernel_41482/3460679292.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f\"Lag_{lag}\"] = data[\"Target\"].shift(-(lag))\n",
      "/var/folders/4c/gx6ft8qx2c90jb6mwvlx3gcw0000gn/T/ipykernel_41482/3460679292.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f\"Lag_{lag}\"] = data[\"Target\"].shift(-(lag))\n",
      "/var/folders/4c/gx6ft8qx2c90jb6mwvlx3gcw0000gn/T/ipykernel_41482/3460679292.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f\"Lag_{lag}\"] = data[\"Target\"].shift(-(lag))\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# STEP 3: Create lag features\n",
    "# -----------------------------------\n",
    "N_LAGS = 5\n",
    "for lag in range(1, N_LAGS + 1):\n",
    "    data[f\"Lag_{lag}\"] = data[\"Target\"].shift(-(lag))\n",
    "# Add lagged date columns\n",
    "for lag in range(1, N_LAGS + 1):\n",
    "    data[f\"Date_Lag_{lag}\"] = data[\"Date\"].shift(-lag)\n",
    "\n",
    "data.dropna(inplace=True)  # drop rows with NaNs introduced by lagging\n",
    "\n",
    "#data.drop(columns=[\"LogReturn\"], inplace=True) # LogReturn no more needed\n",
    "print(data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date  LogReturn  Target     Lag_1     Lag_2     Lag_3     Lag_4  \\\n",
      "0     12/20/2023  -0.002719       0 -0.971119  1.029740  1.030880 -0.968972   \n",
      "1     12/19/2023   0.010115       0  1.029740  1.029740 -0.970045  1.032022   \n",
      "2     12/18/2023   0.003088       1  1.029740 -0.971119  1.030880  1.032022   \n",
      "3     12/15/2023   0.005019       1 -0.971119  1.029740  1.030880 -0.968972   \n",
      "4     12/14/2023  -0.009539       0  1.029740  1.029740 -0.970045 -0.968972   \n",
      "...          ...        ...     ...       ...       ...       ...       ...   \n",
      "2257  01/15/2015   0.007892       1  1.029740  1.029740  1.030880 -0.968972   \n",
      "2258  01/14/2015   0.017121       1  1.029740  1.029740 -0.970045 -0.968972   \n",
      "2259  01/13/2015  -0.023780       1  1.029740 -0.971119 -0.970045 -0.968972   \n",
      "2260  01/12/2015   0.006253       1 -0.971119 -0.971119 -0.970045  1.032022   \n",
      "2261  01/09/2015   0.000043       0 -0.971119 -0.971119  1.030880  1.032022   \n",
      "\n",
      "         Lag_5  lag1_dow_sin  lag1_dow_cos  ...  lag4_month_sin  \\\n",
      "0     1.032022      0.818303      0.935075  ...        0.034720   \n",
      "1     1.032022     -0.699686      1.423076  ...        0.034720   \n",
      "2    -0.968972     -1.542107     -1.040799  ...        0.034720   \n",
      "3    -0.968972      0.142734     -1.040799  ...        0.034720   \n",
      "4     1.032022      1.193215     -0.161453  ...        0.034720   \n",
      "...        ...           ...           ...  ...             ...   \n",
      "2257 -0.968972      1.193215     -0.161453  ...        0.744019   \n",
      "2258 -0.968972      0.818303      0.935075  ...        0.744019   \n",
      "2259  1.032022     -0.699686      1.423076  ...        0.744019   \n",
      "2260  1.032022     -1.542107     -1.040799  ...        0.744019   \n",
      "2261 -0.968972      0.142734     -1.040799  ...        0.744019   \n",
      "\n",
      "      lag4_month_cos  lag4_dom_sin  lag4_dom_cos  lag5_dow_sin  lag5_dow_cos  \\\n",
      "0           1.384770      0.410734     -1.319323      1.192019     -0.161986   \n",
      "1           1.384770      0.670703     -1.205019      0.817007      0.934862   \n",
      "2           1.384770      0.902894     -1.039437     -0.701384      1.423006   \n",
      "3           1.384770      1.097800     -0.829357     -1.544028     -1.041590   \n",
      "4           1.384770      1.388531     -0.025065      0.141259     -1.041590   \n",
      "...              ...           ...           ...           ...           ...   \n",
      "2257        1.195704      1.345692     -0.311572      0.141259     -1.041590   \n",
      "2258        1.195704      1.388531     -0.025065      1.192019     -0.161986   \n",
      "2259        1.195704      1.374202      0.264412      0.817007      0.934862   \n",
      "2260        1.195704      1.303294      0.545008     -0.701384      1.423006   \n",
      "2261        1.195704      1.178708      0.805236     -1.544028     -1.041590   \n",
      "\n",
      "      lag5_month_sin  lag5_month_cos  lag5_dom_sin  lag5_dom_cos  \n",
      "0           0.035385        1.385718      0.671164     -1.205019  \n",
      "1           0.035385        1.385718      0.903353     -1.039437  \n",
      "2           0.035385        1.385718      1.098259     -0.829357  \n",
      "3           0.035385        1.385718      1.388989     -0.025065  \n",
      "4           0.035385        1.385718      1.374660      0.264412  \n",
      "...              ...             ...           ...           ...  \n",
      "2257        0.744406        1.196576      1.388989     -0.025065  \n",
      "2258        0.744406        1.196576      1.374660      0.264412  \n",
      "2259        0.744406        1.196576      1.303752      0.545008  \n",
      "2260        0.744406        1.196576      1.179167      0.805236  \n",
      "2261        0.744406        1.196576      0.544008      1.363905  \n",
      "\n",
      "[2262 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# STEP 4: Add temporal features\n",
    "# -----------------------------------\n",
    "\n",
    "# Helper to add cyclical features for a given date column\n",
    "def add_cyclical_features(df, date_col, prefix):\n",
    "    # Ensure the date column is in datetime format\n",
    "    df[date_col] = pd.to_datetime(df[date_col], format=\"%m/%d/%Y\")\n",
    "    \n",
    "    # Extract raw features\n",
    "    df[f\"{prefix}_day_of_week\"] = df[date_col].dt.dayofweek   # 0-6\n",
    "    df[f\"{prefix}_month\"] = df[date_col].dt.month             # 1-12\n",
    "    df[f\"{prefix}_day_of_month\"] = df[date_col].dt.day        # 1-31\n",
    "\n",
    "    # Day of week: 0-6, max_value=7\n",
    "    df[f\"{prefix}_dow_sin\"] = np.sin(2 * np.pi * df[f\"{prefix}_day_of_week\"] / 7)\n",
    "    df[f\"{prefix}_dow_cos\"] = np.cos(2 * np.pi * df[f\"{prefix}_day_of_week\"] / 7)\n",
    "    # Month: 1-12, max_value=12\n",
    "    df[f\"{prefix}_month_sin\"] = np.sin(2 * np.pi * df[f\"{prefix}_month\"] / 12)\n",
    "    df[f\"{prefix}_month_cos\"] = np.cos(2 * np.pi * df[f\"{prefix}_month\"] / 12)\n",
    "    # Day of month: 1-31, max_value=31\n",
    "    df[f\"{prefix}_dom_sin\"] = np.sin(2 * np.pi * df[f\"{prefix}_day_of_month\"] / 31)\n",
    "    df[f\"{prefix}_dom_cos\"] = np.cos(2 * np.pi * df[f\"{prefix}_day_of_month\"] / 31)\n",
    "\n",
    "# Add cyclical features for each lagged date column\n",
    "for lag in range(1, N_LAGS + 1):\n",
    "    lag_col = f\"Date_Lag_{lag}\"\n",
    "    add_cyclical_features(data, lag_col, f\"lag{lag}\")\n",
    "\n",
    "# Learn a scaler on the first 80% of the dataset, then apply to all sin and cos columns\n",
    "full_train_size = int(len(data) * 0.8)\n",
    "sin_cos_cols = [col for col in data.columns if col.endswith(\"_sin\") or col.endswith(\"_cos\") or col.startswith(\"Lag\")]\n",
    "scaler_cyc = StandardScaler()\n",
    "scaler_cyc.fit(data.loc[:full_train_size-1, sin_cos_cols])\n",
    "data[sin_cos_cols] = scaler_cyc.transform(data[sin_cos_cols])\n",
    "\n",
    "cols_to_drop = [col for col in data.columns if col.startswith(\"Date_Lag_\") or \n",
    "            col.endswith(\"_day_of_week\") or col.endswith(\"_month\") or col.endswith(\"_day_of_month\")]\n",
    "data.drop(columns=cols_to_drop, inplace=True)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"FTSE100_classification_easy.csv\", index=False)\n",
    "#data.to_csv(\"SP500_classification_easy.csv\", index=False)\n",
    "#data.to_csv(\"DAX_classification_easy.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
